{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "550bd43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "181b2e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = pd.read_csv('wsb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a0002c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lol. Yeah, Welp.</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-10-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crypto miners is not a significant enough mark...</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-02-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sold a covered call at 560. I almost wish it d...</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NFLX because earning reports releases. +10-12%...</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agreed 100%. When are their earnings? I'd like...</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-07-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  score        date\n",
       "0                                   Lol. Yeah, Welp.      1  2014-10-09\n",
       "1  Crypto miners is not a significant enough mark...      1  2014-02-19\n",
       "2  Sold a covered call at 560. I almost wish it d...      1  2014-04-24\n",
       "3  NFLX because earning reports releases. +10-12%...      1  2014-01-20\n",
       "4  Agreed 100%. When are their earnings? I'd like...      1  2014-07-25"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19bdc40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                           Lol. Yeah, Welp.\n",
       "1          Crypto miners is not a significant enough mark...\n",
       "2          Sold a covered call at 560. I almost wish it d...\n",
       "3          NFLX because earning reports releases. +10-12%...\n",
       "4          Agreed 100%. When are their earnings? I'd like...\n",
       "                                 ...                        \n",
       "2815058                  All I gotta say is... calm yo tits.\n",
       "2815059                                     true tho in't it\n",
       "2815060    Gold is a key element in electronics. The bot ...\n",
       "2815061    Listen up kids as I tell you how I earned my f...\n",
       "2815062    sometimes you should sell with a loss. Jnug ha...\n",
       "Name: body, Length: 2815063, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data['body']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae347f2",
   "metadata": {},
   "source": [
    "## Lets Get the length of the characters present in 'body' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a861f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_len(text):\n",
    "    body_cont_len = len(str(text))\n",
    "    return body_cont_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e067bd41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            16\n",
       "1           434\n",
       "2           159\n",
       "3            72\n",
       "4            71\n",
       "           ... \n",
       "2815058      35\n",
       "2815059      16\n",
       "2815060      58\n",
       "2815061    1662\n",
       "2815062     232\n",
       "Name: cont_len, Length: 2815063, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data['cont_len'] = json_data['body'].apply(get_len)\n",
    "json_data['cont_len']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4252058d",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "Let's get the sentiment Analysis from the content of body.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3d5f429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob,Word\n",
    "import unicodedata\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde06c96",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning\n",
    "    \n",
    "    We can see the content of 'body' column is not a clean data. It contains lots of \n",
    "    i. Punctuations\n",
    "    ii. Numbers\n",
    "    iii. Stopwords \n",
    "    These things is not going to give any value to the text but only increase the consumption of memory. So, before going for Sentimental Analysis let's clean the data.\n",
    "\n",
    "### i. Remove Punctuations\n",
    "     Let's clean all the Punctuations like ?, !, # and so on from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d35c0127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(text):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    word = str(text).translate(translator) \n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77364e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                              Lol Yeah Welp\n",
       "1          Crypto miners is not a significant enough mark...\n",
       "2          Sold a covered call at 560 I almost wish it dr...\n",
       "3          NFLX because earning reports releases 1012 for...\n",
       "4          Agreed 100 When are their earnings Id like to ...\n",
       "                                 ...                        \n",
       "2815058                      All I gotta say is calm yo tits\n",
       "2815059                                      true tho int it\n",
       "2815060    Gold is a key element in electronics The bot h...\n",
       "2815061    Listen up kids as I tell you how I earned my f...\n",
       "2815062    sometimes you should sell with a loss Jnug has...\n",
       "Name: body, Length: 2815063, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data['body'] = json_data['body'].apply(remove_punctuations)\n",
    "json_data['body']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e45168f",
   "metadata": {},
   "source": [
    "### ii. Remove Numbers\n",
    "\n",
    "    Let's remove all the numbers from the text since it not going to add any value in the text for Sentimental Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc111e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(text):   \n",
    "    pat = r'[0-9]'\n",
    "    nltk_cleaned = re.sub(pat,'',text)\n",
    "    return nltk_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c46e4d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                              Lol Yeah Welp\n",
       "1          Crypto miners is not a significant enough mark...\n",
       "2          Sold a covered call at  I almost wish it drops...\n",
       "3          NFLX because earning reports releases  for the...\n",
       "4          Agreed  When are their earnings Id like to jum...\n",
       "                                 ...                        \n",
       "2815058                      All I gotta say is calm yo tits\n",
       "2815059                                      true tho int it\n",
       "2815060    Gold is a key element in electronics The bot h...\n",
       "2815061    Listen up kids as I tell you how I earned my f...\n",
       "2815062    sometimes you should sell with a loss Jnug has...\n",
       "Name: body, Length: 2815063, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data['body'] = json_data.apply(lambda x: remove_numbers(x['body']),axis =1)\n",
    "json_data['body']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8421ba",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Remove Special and Accented Characters\n",
    "\n",
    "    Special/Accented Characters like a`,b`,... will not add any value in the text. So, let's remove it from the text.\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a2608e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accented_chars(text):\n",
    "    nltk_accented = unicodedata.normalize('NFKD',text).encode('ascii','ignore').decode('utf-8','ignore')\n",
    "    return nltk_accented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f159072d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                              Lol Yeah Welp\n",
       "1          Crypto miners is not a significant enough mark...\n",
       "2          Sold a covered call at  I almost wish it drops...\n",
       "3          NFLX because earning reports releases  for the...\n",
       "4          Agreed  When are their earnings Id like to jum...\n",
       "                                 ...                        \n",
       "2815058                      All I gotta say is calm yo tits\n",
       "2815059                                      true tho int it\n",
       "2815060    Gold is a key element in electronics The bot h...\n",
       "2815061    Listen up kids as I tell you how I earned my f...\n",
       "2815062    sometimes you should sell with a loss Jnug has...\n",
       "Name: body, Length: 2815063, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data['body'] = json_data.apply(lambda x: remove_accented_chars(x['body']),axis =1)\n",
    "json_data['body']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627e435c",
   "metadata": {},
   "source": [
    "# 2. Tokenization\n",
    "\n",
    "    Tokens helps to know the meaning of text. So, lets break the text into smaller units, Here we'll go for word tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad5728b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(text):\n",
    "    nltk_tokens = nltk.word_tokenize(str(text))         \n",
    "    return nltk_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58040da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                          [Lol, Yeah, Welp]\n",
       "1          [Crypto, miners, is, not, a, significant, enou...\n",
       "2          [Sold, a, covered, call, at, I, almost, wish, ...\n",
       "3          [NFLX, because, earning, reports, releases, fo...\n",
       "4          [Agreed, When, are, their, earnings, Id, like,...\n",
       "                                 ...                        \n",
       "2815058           [All, I, got, ta, say, is, calm, yo, tits]\n",
       "2815059                                 [true, tho, int, it]\n",
       "2815060    [Gold, is, a, key, element, in, electronics, T...\n",
       "2815061    [Listen, up, kids, as, I, tell, you, how, I, e...\n",
       "2815062    [sometimes, you, should, sell, with, a, loss, ...\n",
       "Name: body, Length: 2815063, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data['body'] = json_data['body'].apply(get_tokens)\n",
    "json_data['body']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a52d1a",
   "metadata": {},
   "source": [
    "# 3. Remove Stop words\n",
    "\n",
    "    Stopwords like The, And, Myself, this.... will not add much value to the sentence.So, its better to get rid of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5ebe18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/bidhya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e11b72a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    clean_text = [word for word in text if not word.lower() in stop_words]\n",
    "#     clean_text = []\n",
    "    \n",
    "#     for word in text:\n",
    "#     if word not in stop_words:\n",
    "#         clean_text.append(word)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15ef2f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                          [Lol, Yeah, Welp]\n",
       "1          [Crypto, miners, significant, enough, market, ...\n",
       "2          [Sold, covered, call, almost, wish, drops, bac...\n",
       "3            [NFLX, earning, reports, releases, week, guess]\n",
       "4             [Agreed, earnings, Id, like, jump, puts, well]\n",
       "                                 ...                        \n",
       "2815058                       [got, ta, say, calm, yo, tits]\n",
       "2815059                                     [true, tho, int]\n",
       "2815060        [Gold, key, element, electronics, bot, hates]\n",
       "2815061    [Listen, kids, tell, earned, flair, January, l...\n",
       "2815062    [sometimes, sell, loss, Jnug, hasnt, since, Tr...\n",
       "Name: body, Length: 2815063, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data['body'] = json_data.apply(lambda x: remove_stopwords(x['body']),axis =1)\n",
    "json_data['body']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236bac2e",
   "metadata": {},
   "source": [
    "# 4. Lemmatization\n",
    "\n",
    "    Since, Lemmatization reduces the word to its dictionary form. Lets do lemmatization over stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9be99e96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import spacy\n",
    "\n",
    "# nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3533d903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_lem(text):\n",
    "#     text = nlp(text)\n",
    "#     text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "#     return text\n",
    "\n",
    "def get_lem(text):\n",
    "    lem_word= [Word(word).lemmatize(\"v\") for word in text]\n",
    "    return lem_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "001186d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                          [Lol, Yeah, Welp]\n",
       "1          [Crypto, miners, significant, enough, market, ...\n",
       "2          [Sold, cover, call, almost, wish, drop, back, ...\n",
       "3                 [NFLX, earn, report, release, week, guess]\n",
       "4                  [Agreed, earn, Id, like, jump, put, well]\n",
       "                                 ...                        \n",
       "2815058                       [get, ta, say, calm, yo, tits]\n",
       "2815059                                     [true, tho, int]\n",
       "2815060          [Gold, key, element, electronics, bot, hat]\n",
       "2815061    [Listen, kid, tell, earn, flair, January, last...\n",
       "2815062    [sometimes, sell, loss, Jnug, hasnt, since, Tr...\n",
       "Name: body, Length: 2815063, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data['body'] = json_data.apply(lambda x: get_lem(x['body']),axis =1)\n",
    "json_data['body']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2d454a",
   "metadata": {},
   "source": [
    "## Convert the list to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1550679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_string(text):\n",
    "    listToStr = ' '.join([str(elem) for elem in text])\n",
    "    return listToStr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a378d355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                              Lol Yeah Welp\n",
       "1          Crypto miners significant enough market yet AM...\n",
       "2          Sold cover call almost wish drop back bite thi...\n",
       "3                        NFLX earn report release week guess\n",
       "4                          Agreed earn Id like jump put well\n",
       "                                 ...                        \n",
       "2815058                              get ta say calm yo tits\n",
       "2815059                                         true tho int\n",
       "2815060                 Gold key element electronics bot hat\n",
       "2815061    Listen kid tell earn flair January last year m...\n",
       "2815062    sometimes sell loss Jnug hasnt since Trump ele...\n",
       "Name: body, Length: 2815063, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data['body'] = json_data.apply(lambda x: list_to_string(x['body']),axis =1)\n",
    "json_data['body']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43c2bce",
   "metadata": {},
   "source": [
    "# 5. Get Polarity\n",
    "\n",
    "    More than personal opinion, we prefer sentimental aspect of an opinion. So, Lets go for Polarity.\n",
    "    \n",
    "    i. Lets get the polarity in number first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0bff88a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polarity(text):\n",
    "    textblob = TextBlob(str(text.encode('utf-8')))\n",
    "    pol = textblob.sentiment.polarity\n",
    "        \n",
    "    return pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69971156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0.800000\n",
       "1         -0.037771\n",
       "2          0.000000\n",
       "3          0.000000\n",
       "4          0.000000\n",
       "             ...   \n",
       "2815058    0.300000\n",
       "2815059    0.350000\n",
       "2815060    0.000000\n",
       "2815061    0.057047\n",
       "2815062    0.000000\n",
       "Name: cont_pol, Length: 2815063, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data['cont_pol'] = json_data.apply(lambda x: get_polarity(x['body']),axis =1)\n",
    "json_data['cont_pol'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b27979",
   "metadata": {},
   "source": [
    "`ii. Let's Analyze if the polarity sentiment is 'Positive', 'Negative' or 'Neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61173801",
   "metadata": {},
   "outputs": [],
   "source": [
    " def analysis(score):\n",
    "    if score < 0:\n",
    "        return 'Negative'\n",
    "    elif score > 0:\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return 'Neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af5208bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data['cont_sent'] = json_data.apply(lambda x: analysis(x['cont_pol']),axis =1)\n",
    "json_data['cont_sent'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "074b5014",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7d4d5a",
   "metadata": {},
   "source": [
    "## Let's drop 'body' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1fc9fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = json_data.drop(columns='body')\n",
    "json_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c829b9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data['date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1528e1",
   "metadata": {},
   "source": [
    "# 6. Save the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae065a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data.to_csv('analyzedJSON_data.csv') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
